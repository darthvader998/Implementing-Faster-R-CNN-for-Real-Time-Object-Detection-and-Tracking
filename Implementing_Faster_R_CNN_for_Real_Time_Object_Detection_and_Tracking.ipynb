{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UNB-TME-6017-W24/assignment-3-darthvader998/blob/main/3721371_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uFA2S8krL37S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Research and Model Selection\n",
        "\n",
        " Given the need for real-time object detection and tracking with a balanced approach to speed and accuracy, Faster R-CNN model as the pre-trained model would be suitable for this project.\n",
        "\n",
        " Justifying the choice of the Faster R-CNN model over others, such as YOLO (You Only Look Once) or SSD (Single Shot MultiBox Detector) after considering its balance between speed and accuracy, which is crucial for our requirements. Although models like YOLO and SSD offer faster inference times, which are beneficial for real-time detection tasks, Faster R-CNN tends to achieve higher accuracy.\n",
        "\n",
        "In the first stage, Faster R-CNN uses a Region Proposal Network (RPN) to generate potential bounding boxes in an image that are likely to contain objects. In the second stage, it refines these bounding boxes and classifies the objects within them. This two-step approach allows for more precise detections and a lower false positive rate, as it explicitly differentiates between background and foreground, making it ideal for applications where precision is paramount.\n",
        "\n",
        "Furthermore, the ability of Faster R-CNN to integrate with deep feature extractors like ResNet makes it highly adaptable for a wide range of object detection tasks, as these deep networks can capture intricate details and subtle features of objects. This is particularly advantageous in scenarios where the dataset is complex and contains objects that require detailed feature extraction for accurate detection and classification.\n",
        "\n",
        "For our dataset, which is based on the COCO 2017 challenge, Faster R-CNN offers a robust and tested solution. The dataset contains a diverse set of images with complex scenes and multiple object categories, where the model's accuracy and ability to detect small to medium-sized objects align well with our objectives. While it might not provide the real-time inference capabilities of YOLO or SSD, the project prioritizes accuracy and thorough detection over speed, justifying the choice of Faster R-CNN.\n",
        "\n",
        "Additionally, given the project's focus on tracking, the accurate detection of objects frame by frame is critical. Faster R-CNN’s precise bounding box predictions facilitate more reliable tracking across frames, which is beneficial for maintaining the identity of objects over time.\n",
        "\n",
        "In summary, while YOLO and SSD are suitable for scenarios where speed is a critical factor, the selection of Faster R-CNN for this project is justified by its superior accuracy, reliable performance on benchmark datasets, and its suitability for the project's specific needs around precise object detection and tracking."
      ],
      "metadata": {
        "id": "Cz8NH180Tawf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Collection and Preparation\n",
        "\n",
        "\n",
        "For a project involving object detection and tracking, choosing a dataset that not only includes diverse instances of the objects of interest but also should provide continuity for tracking. Therefore, the COCO Dataset seems to be appropriate for this project.\n",
        "\n",
        "The Common Objects in Context (COCO) dataset is widely used in object detection, segmentation, and captioning projects. It offers a large variety of images with objects in their natural contexts and includes annotations for object detection tasks.\n",
        "\n",
        "\n",
        "Used FiftyOne to load and work with the COCO 2017 dataset as downloading the dataset directly from the official coco dataset website required a lot of storage. FiftyOne provides a high-level interface for loading datasets, visualizing data, and integrating with various machine learning models and datasets."
      ],
      "metadata": {
        "id": "vEpcagCDqWa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l78fZQcSh33D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6352b4aa-2b66-4558-a8a4-21cabcdb3c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.23.7-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.2.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.12.3)\n",
            "Collecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.34.79-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.3)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Collecting Deprecated (from fiftyone)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading hypercorn-0.16.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.3)\n",
            "Collecting kaleido!=0.2.1.post1 (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n",
            "Collecting mongoengine==0.24.2 (from fiftyone)\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.4.0-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (24.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2.0.3)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo>=3.12 (from fiftyone)\n",
            "  Downloading pymongo-4.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (676 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.12.25)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Collecting starlette>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting fiftyone-brain<0.17,>=0.16.1 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.16.1-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-1.1.2.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting voxel51-eta<0.13,>=0.12.6 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.12.6-py2.py3-none-any.whl (942 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m942.9/942.9 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.9.0.80)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.10.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain<0.17,>=0.16.1->fiftyone) (1.11.4)\n",
            "Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.3)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n",
            "Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (0.18.3)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (5.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.5)\n",
            "Collecting botocore<1.35.0,>=1.34.79 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.34.79-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fiftyone) (2024.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.6.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.2.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.13,>=0.12.6->fiftyone) (23.2.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.13,>=0.12.6->fiftyone) (3.3.2)\n",
            "Building wheels for collected packages: fiftyone-db\n",
            "  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.2-py3-none-manylinux1_x86_64.whl size=42156164 sha256=524ae2806162e19d7c57a670e2df83bcbb05a22822b8ae9d684b250289924437\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/52/b9/14b9d344410c63c0447ba16bf47c0a064c55d735fa14ecf95c\n",
            "Successfully built fiftyone-db\n",
            "Installing collected packages: texttable, sseclient-py, pprintpp, kaleido, brotli, xmltodict, taskgroup, retrying, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n",
            "Successfully installed Deprecated-1.2.14 aiofiles-23.2.1 argcomplete-3.2.3 boto3-1.34.79 botocore-1.34.79 brotli-1.1.0 dacite-1.7.0 dill-0.3.8 dnspython-2.6.1 fiftyone-0.23.7 fiftyone-brain-0.16.1 fiftyone-db-1.1.2 ftfy-6.2.0 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hypercorn-0.16.0 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.4.0 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pymongo-4.6.3 pyppmd-1.1.0 pyzstd-0.15.10 rarfile-4.2 retrying-1.3.4 s3transfer-0.10.1 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.37.2 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.12.6 wsproto-1.2.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "pip install fiftyone\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Loading COCO 2017 Training Dataset\n",
        "train_dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"train\",\n",
        "    dataset_name=\"coco-2017-train\"\n",
        ")\n",
        "\n",
        "# Loading COCO 2017 Validation Dataset\n",
        "validation_dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    dataset_name=\"coco-2017-validation\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvfZI9S1yO0z",
        "outputId": "f0841661-97ea-4ee7-c892-0f156a23e113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.23.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.23.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [17.0s elapsed, 0s remaining, 129.4Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [17.0s elapsed, 0s remaining, 129.4Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/train2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/train2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |████|  144.1Gb/144.1Gb [20.0m elapsed, 0s remaining, 132.1Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |████|  144.1Gb/144.1Gb [20.0m elapsed, 0s remaining, 132.1Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/train/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/train/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████| 118287/118287 [16.9m elapsed, 0s remaining, 143.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████| 118287/118287 [16.9m elapsed, 0s remaining, 143.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-train' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    6.1Gb/6.1Gb [58.6s elapsed, 0s remaining, 135.1Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    6.1Gb/6.1Gb [58.6s elapsed, 0s remaining, 135.1Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 5000/5000 [38.8s elapsed, 0s remaining, 159.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 5000/5000 [38.8s elapsed, 0s remaining, 159.3 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-validation' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation' created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Defining the augmentation pipeline\n",
        "augmentations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "q1CGOrIz6TuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing to match the input requirements of the model\n",
        "transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sckvz2hT6X5C",
        "outputId": "26e7aa97-46ca-40b0-9403-f6b98ef29bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o1vhPsdb6bI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Implementation\n",
        "\n",
        "A pre-trained Faster R-CNN model is loaded using PyTorch, configured to run on a GPU if available.\n",
        "The model is set to evaluation mode, which is standard procedure when performing inference as it disables certain layers and behaviors like Dropout or BatchNorm that are only used during training.\n",
        "A random subset of 100 samples is selected from the training dataset to which predictions will be added."
      ],
      "metadata": {
        "id": "52hw8olBU1UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Running the model on GPU only if it is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Loading a pre-trained Faster R-CNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwBVxo0K9WU9",
        "outputId": "342e8266-98c9-4d1f-b873-83b1356d4bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:02<00:00, 57.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing a random subset of 100 samples to add predictions to\n",
        "predictions_view = train_dataset.take(100, seed=51)"
      ],
      "metadata": {
        "id": "Zo20zFZu9a1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Detection:**\n",
        "Adding predictions to each randomly selected samples. This involves loading images, converting them to tensors, and feeding them into the model.\n",
        "The outputs from the model (labels, scores, and bounding boxes) are converted into the FiftyOne format, which is used for visualization and analysis in the FiftyOne app."
      ],
      "metadata": {
        "id": "SV7erjHlfpkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import functional as func\n",
        "\n",
        "import fiftyone as fo\n",
        "\n",
        "# Getting class list from the dataset\n",
        "classes = train_dataset.default_classes\n",
        "\n",
        "# Adding predictions to samples\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(predictions_view):\n",
        "        # Loading image\n",
        "        image = Image.open(sample.filepath)\n",
        "        image = func.to_tensor(image).to(device)\n",
        "        c, h, w = image.shape\n",
        "\n",
        "        # Performing inference\n",
        "        preds = model([image])[0]\n",
        "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
        "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
        "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
        "\n",
        "        # Converting detections to FiftyOne format\n",
        "        detections = []\n",
        "        for label, score, box in zip(labels, scores, boxes):\n",
        "            # Converting to [top-left-x, top-left-y, width, height]\n",
        "            # in relative coordinates in [0, 1] x [0, 1]\n",
        "            x1, y1, x2, y2 = box\n",
        "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
        "\n",
        "            detections.append(\n",
        "                fo.Detection(\n",
        "                    label=classes[label],\n",
        "                    bounding_box=rel_box,\n",
        "                    confidence=score\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Saving predictions to dataset\n",
        "        sample[\"predictions\"] = fo.Detections(detections=detections)\n",
        "        sample.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNg7Dqj29qSI",
        "outputId": "463b04c1-bf4f-42c2-d2cc-ed1f72ad7a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 100/100 [13.4m elapsed, 0s remaining, 0.1 samples/s]    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 100/100 [13.4m elapsed, 0s remaining, 0.1 samples/s]    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used FiftyOne tool to load and work with the dataset"
      ],
      "metadata": {
        "id": "mx3ekY3vferr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "\n",
        "session = fo.launch_app()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s1IxfhzOBud2",
        "outputId": "401932dc-38ce-446e-801e-b394eaf8d62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5\">\n",
              "      <button id=\"foactivate-837b1b6d-a9a5-4f8c-8dda-8f06f86294f5\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Welcome to\n",
            "\n",
            "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
            "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
            "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
            "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
            "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
            "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v0.23.7\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  🚀🚀🚀 Join the FiftyOne Slack community 🚀🚀🚀\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.session.session:\n",
            "Welcome to\n",
            "\n",
            "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
            "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
            "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
            "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
            "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
            "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v0.23.7\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  🚀🚀🚀 Join the FiftyOne Slack community 🚀🚀🚀\n",
            "|  https://slack.voxel51.com\n",
            "|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session.view = predictions_view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "id": "LU7xFmHnBP3b",
        "outputId": "9b402312-cdda-4165-cd3a-85bca6545385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd\">\n",
              "      <button id=\"foactivate-709806b4-a2f9-4f53-9fb0-6b53b8f08ccd\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "For inference after loading predictions_view in the App to visualize the predictions that we added. In this image from what appears to be the FiftyOne app where an individual, seemingly a man, making a speech or presentation. The man is wearing a formal suit with a red patterned bow tie and a name tag, and he's holding a microphone., you can see that there are several tags or labels in the sidebar pertaining to the machine learning dataset: ground_truth, predictions.\n",
        "\n",
        "\n",
        "**Ground Truth (2):** There are 2 annotations provided as ground truth for the objects within the image. Ground truth annotations are considered the correct answer or the benchmark for model predictions. These could be bounding boxes or other forms of labels that indicate the presence and position of objects in the image that the model is meant to detect.\n",
        "\n",
        "**Predictions (24):** A trained model has produced 24 predictions for this particular image. These predictions are the model's attempt to detect objects based on what it has learned during training. The number of predictions exceeds the ground truth, suggesting that the model may have identified multiple potential objects that need further validation to determine their accuracy. This could indicate a high recall rate, but potentially also a lower precision if many of these predictions are false positives.\n",
        "\n"
      ],
      "metadata": {
        "id": "0gxpeVjLNf8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object Tracking:**\n",
        "A CentroidTracker class is defined and implemented, which updates the tracker with detections for each frame.\n",
        "The centroid tracker is used to maintain the identity of objects across frames.\n",
        "\n",
        "The tracker is initialized, registered, deregistered, and updated for tracking."
      ],
      "metadata": {
        "id": "IjSsnrvLgAKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "\n",
        "class CentroidTracker:\n",
        "    def __init__(self, maxDisappeared=50):\n",
        "        # Initializing the next unique object ID along with two ordered dictionaries\n",
        "        self.nextObjectID = 0\n",
        "        self.objects = {}\n",
        "        self.disappeared = {}\n",
        "\n",
        "        # Storing the maximum number of consecutive frames a given object is\n",
        "        # marked as \"disappeared\" until we deregister the object from tracking\n",
        "        self.maxDisappeared = maxDisappeared\n",
        "\n",
        "    def register(self, centroid):\n",
        "        # While registering an object, used the next available object ID to store the\n",
        "        # centroid coordinates of the object\n",
        "        self.objects[self.nextObjectID] = centroid\n",
        "        self.disappeared[self.nextObjectID] = 0\n",
        "        self.nextObjectID += 1\n",
        "\n",
        "    def deregister(self, objectID):\n",
        "        # To deregister an object ID, deleted the object ID from both of our\n",
        "        # respective dictionaries\n",
        "        del self.objects[objectID]\n",
        "        del self.disappeared[objectID]\n",
        "\n",
        "    def update(self, rects):\n",
        "        # Checking to see if the list of input bounding box rectangles is empty\n",
        "        if len(rects) == 0:\n",
        "            # Looping over any existing tracked objects and marking them as disappeared\n",
        "            for objectID in list(self.disappeared.keys()):\n",
        "                self.disappeared[objectID] += 1\n",
        "\n",
        "                # Deregistering any object if a maximum number of frames is reached where the object has\n",
        "                # been marked as missing\n",
        "                if self.disappeared[objectID] > self.maxDisappeared:\n",
        "                    self.deregister(objectID)\n",
        "\n",
        "            # Returning early as there are no centroids or tracking info to update\n",
        "            return self.objects\n",
        "\n",
        "        # Initializing an array of input centroids for the current frame\n",
        "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
        "\n",
        "        # Looping over the bounding box rectangles\n",
        "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
        "            # Use the bounding box coordinates to derive the centroid\n",
        "            cX = int((startX + endX) / 2.0)\n",
        "            cY = int((startY + endY) / 2.0)\n",
        "            inputCentroids[i] = (cX, cY)\n",
        "\n",
        "        # If we are currently not tracking any objects take the input centroids and\n",
        "        # register each of them\n",
        "        if len(self.objects) == 0:\n",
        "            for i in range(0, len(inputCentroids)):\n",
        "                self.register(inputCentroids[i])\n",
        "\n",
        "        # Otherwise, we are currently tracking objects so we need to try to match the\n",
        "        # input centroids to existing object centroids\n",
        "        else:\n",
        "            # Getting the set of object IDs and corresponding centroids\n",
        "            objectIDs = list(self.objects.keys())\n",
        "            objectCentroids = list(self.objects.values())\n",
        "\n",
        "            # Computing the distance between each pair of object centroids and input centroids,\n",
        "            # respectively -- the goal will be to match an input centroid to an existing\n",
        "            # object centroid\n",
        "            D = distance.cdist(np.array(objectCentroids), inputCentroids)\n"
      ],
      "metadata": {
        "id": "-uHGD2u7Z1m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the tracker\n",
        "tracker = CentroidTracker()\n",
        "\n",
        "# Looping to process images, perform detection, update the tracker, and store results in FiftyOne\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(predictions_view):\n",
        "        # Loading image\n",
        "        image = Image.open(sample.filepath)\n",
        "        image = func.to_tensor(image).to(device)\n",
        "        c, h, w = image.shape\n",
        "\n",
        "        # Performing inference\n",
        "        preds = model([image])[0]\n",
        "        labels = preds['labels'].cpu().detach().numpy()\n",
        "        scores = preds['scores'].cpu().detach().numpy()\n",
        "        boxes = preds['boxes'].cpu().detach().numpy()\n",
        "\n",
        "        # Updating the tracker with detections from the current frame\n",
        "        # Here we assume that 'boxes' are in the format [x1, y1, x2, y2]\n",
        "        detections = [(box[0], box[1], box[2] - box[0], box[3] - box[1]) for box in boxes]\n",
        "        tracker.update(detections)\n",
        "\n",
        "                # Converting detections to FiftyOne format\n",
        "        model_detections = []\n",
        "        for label, score, box in zip(labels, scores, boxes):\n",
        "            x1, y1, x2, y2 = box\n",
        "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
        "\n",
        "            model_detections.append(\n",
        "                fo.Detection(\n",
        "                    label=classes[label],\n",
        "                    bounding_box=rel_box,\n",
        "                    confidence=score\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Adding model detections to the sample\n",
        "        sample[\"predictions\"] = fo.Detections(detections=model_detections)\n",
        "\n",
        "        # Preparing FiftyOne for tracking results\n",
        "        tracking_results = []\n",
        "        for objectID, centroid in tracker.objects.items():\n",
        "            # Here we need to check the length of the centroid tuple\n",
        "            # If the tracker returns 2 values, we need to convert it to 4 values\n",
        "            if len(centroid) == 4:\n",
        "                x, y, width, height = centroid\n",
        "                x1 = max(0, x - (width / 2))\n",
        "                y1 = max(0, y - (height / 2))\n",
        "            else:\n",
        "                # This is just a placeholder, in case the tracker returns only (cX, cY)\n",
        "                # We would need the width and height to create a proper bounding box\n",
        "                x, y = centroid\n",
        "                width, height = 50, 50  # Placeholder values for width and height\n",
        "                x1 = max(0, x - (width / 2))\n",
        "                y1 = max(0, y - (height / 2))\n",
        "\n",
        "            # Converting centroid to FiftyOne bounding box format\n",
        "            rel_box = [x1 / w, y1 / h, width / w, height / h]\n",
        "\n",
        "            tracking_results.append(\n",
        "                fo.Detection(\n",
        "                    label=str(objectID),\n",
        "                    bounding_box=rel_box\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Adding tracking results to the sample\n",
        "        sample[\"tracking\"] = fo.Detections(detections=tracking_results)\n",
        "        sample.save()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEYKQ8IzbxIS",
        "outputId": "5a1e38c8-cab5-4817-981b-42381202c913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 100/100 [13.7m elapsed, 0s remaining, 0.1 samples/s]    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 100/100 [13.7m elapsed, 0s remaining, 0.1 samples/s]    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launching FiftyOne session\n",
        "session = fo.launch_app()\n",
        "\n",
        "# Using the dataset with added predictions and tracking\n",
        "session.dataset = train_dataset\n",
        "\n",
        "# Creating a view that includes samples with tracking labels\n",
        "view = train_dataset.exists(\"tracking\")\n",
        "session.view = view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xqOIhxbjgNjH",
        "outputId": "3fd1b2d9-cc92-4966-b8f3-6481515dda7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-1f896b60-4b60-44a5-bdb8-f44e1142bd38 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-1f896b60-4b60-44a5-bdb8-f44e1142bd38 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-1f896b60-4b60-44a5-bdb8-f44e1142bd38:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-1f896b60-4b60-44a5-bdb8-f44e1142bd38 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-1f896b60-4b60-44a5-bdb8-f44e1142bd38\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-1f896b60-4b60-44a5-bdb8-f44e1142bd38\">\n",
              "      <button id=\"foactivate-1f896b60-4b60-44a5-bdb8-f44e1142bd38\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-fa47e566-a120-475e-941c-4713bc810fc8 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-fa47e566-a120-475e-941c-4713bc810fc8 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-fa47e566-a120-475e-941c-4713bc810fc8:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-fa47e566-a120-475e-941c-4713bc810fc8 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-fa47e566-a120-475e-941c-4713bc810fc8\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-fa47e566-a120-475e-941c-4713bc810fc8\">\n",
              "      <button id=\"foactivate-fa47e566-a120-475e-941c-4713bc810fc8\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-8847c1b4-43cf-4f1e-a035-56d94dc6ad96 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-8847c1b4-43cf-4f1e-a035-56d94dc6ad96 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-8847c1b4-43cf-4f1e-a035-56d94dc6ad96:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-8847c1b4-43cf-4f1e-a035-56d94dc6ad96 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-8847c1b4-43cf-4f1e-a035-56d94dc6ad96\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-8847c1b4-43cf-4f1e-a035-56d94dc6ad96\">\n",
              "      <button id=\"foactivate-8847c1b4-43cf-4f1e-a035-56d94dc6ad96\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For inference after applying tracking analyzed this image where social scene with people engaged in an activity, likely at an event or gathering,\n",
        "\n",
        "In this image from what appears to be the FiftyOne app, you can see that there are several tags or labels in the sidebar pertaining to the machine learning dataset: `ground_truth`, `predictions`, and `tracking`.\n",
        "\n",
        "- **Ground Truth (18)**: There are 18 ground truth annotations on this image. Ground truth refers to the actual, manually labeled data indicating the correct answers for the training or evaluation of a machine learning model.\n",
        "\n",
        "- **Predictions (95)**: The model has made 95 predictions for this image. This is typically the output from a trained machine learning model, where it tries to predict the ground truth labels based on the learned patterns.\n",
        "\n",
        "- **Tracking (9)**: The tracking implementation has been applied to this image, resulting in 9 tracking annotations. In the context of object detection and tracking, this likely indicates that the model has identified and tracked 9 distinct objects over time (or across different frames if this is a part of a sequence of images).\n",
        "\n",
        "The discrepancy in the number of ground truth labels and predictions suggests that the model may have either made multiple predictions for the same object or detected additional objects that were not labeled in the ground truth."
      ],
      "metadata": {
        "id": "NGVI1a3ig5UK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges and Future Directions\n",
        "\n",
        "\n",
        "Reflecting on the project details and the nature of object detection and tracking, here are the challenges faced, along with potential future directions:\n",
        "\n",
        "### Challenges Encountered:\n",
        "1. **Dataset Limitations**: While the COCO dataset is comprehensive, it did not cover all edge cases or specific scenarios needed for advanced object detection and tracking. Also, while trying to use the official dataset from COCO website it required a lot of memory so had to use the fiftyOne app to extract the COCO dataset.\n",
        "\n",
        "Refered from : https://docs.voxel51.com/recipes/adding_detections.html\n",
        "   \n",
        "2. **Model Complexity and Speed**: Faster R-CNN, while accurate, it's computationally intensive, which may not be suitable for real-time applications. Balancing model complexity with the need for speed is a constant challenge.\n",
        "\n",
        "3. **Generalization to New Domains**: The model might perform well on the dataset it was trained on but did not generalize well to datasets.\n",
        "\n",
        "### Future Directions:\n",
        "1. **Exploring Lightweight Models**: Investigating more computationally efficient models such as YOLO or SSDLite that could allow for real-time object detection without significant loss of accuracy.\n",
        "\n",
        "2. **Advanced Tracking Algorithms**: Implementing more sophisticated tracking algorithms like SORT or DeepSORT that use additional features beyond simple centroid calculations could improve tracking performance.\n",
        "\n",
        "3. **Semi-supervised Learning**: Utilizing semi-supervised approaches to take advantage of unlabeled data, which could help the model learn better representations and improve detection on less common objects.\n",
        "\n",
        "4. **Continuous Learning**: Implementing a system where the model can continue to learn from new data after deployment, constantly improving its performance over time.\n",
        "\n",
        "By addressing these challenges and exploring the future directions listed, the project can be pushed towards a more robust, accurate, and versatile object detection and tracking system."
      ],
      "metadata": {
        "id": "Cz5saM_EhIO0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zxFDm7jg-cm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}